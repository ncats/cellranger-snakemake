#!/usr/bin/env Rscript
suppressPackageStartupMessages(library(Seurat))
library(data.table)
library(biomaRt)
library(stringr)
library(iterators)
library(optparse)
library(tools)
library(ggplot2)
suppressPackageStartupMessages(library(doParallel))


# NOTE: This script assumes:
# 1. That the files within the supplied directory are all part of the same run
# (This assumption means we can convert a single file's Ensemble Gene IDs into
# Gene Symbols via Ensembl Mart and it will map to all other input files)
# 2. That all .csv files reside within a directory created by the cellranger
# Snakemake pipeline.  This assumption allows us to find the .csv's based upon
# info in the supplied mapping_file

workdir.path <- '.'
map_file_path <- './mapping_file'
num_cores <- 7

# Handle args for command-line runs
if ( !interactive() ) {
  
  option_list = list(
  
    make_option( c( "-w", "--workdir"), type="character", default=".", help="path to working dir", metavar="character" ),
    
    make_option( c( "-m", "--mapfile"), type="character", default="mapping_file", help="mapping file name [default= %default]", metavar="character" ),
    
    make_option( c( "-c", "--numcores"), type="integer", default=7, help="Number of available cores for dopar tasks", metavar="character" )
    
  )
  
  opt_parser = OptionParser( option_list=option_list )
  opt = parse_args( opt_parser )

  if ( !is.null( opt$workdir ) ) {
    workdir.path <- opt$workdir
  }
  
  if ( !is.null( opt$mapfile ) ) {
    map_file_path <- opt$mapfile
  }

  if ( !is.null( opt$numcores ) ) {
    num_cores <- opt$numcores
  }
  
}

registerDoParallel( cores=num_cores )

workdir.path <- normalizePath( workdir.path )
setwd( workdir.path )

# Need to get the path to the input files from the mapping file.
# While doing so, grab other releveant information for later use.

# Create group.map based on map_file.  Bring in library but call it 'project' ala Seurat
map_file <- as.data.frame( read.table( map_file_path ) )
col_names <- c( 'library', 'sample_id', 'file_path', 'lanes', 'library_id', 'group' )
colnames( map_file ) <- col_names
group.map <- data.frame( matrix( ncol=2, nrow=0) )
input_files <- vector()
for ( row in 1:nrow( map_file ) ) {
  
  # Create path for the input .csv file.
  # ( Assume we are running in directory generated by the snakemake pipeline. )
  input_path <- paste0( workdir.path, '/', map_file$library[row], '/outs/', map_file$sample_id[row], '.csv' )
  input_files <- append( input_files, input_path )
  
  # store group-to-sample map, with multiple rows for samples mapping to multiple groups
  if ( grepl( ',', map_file[row,'group'] ) ) {
    
    for ( group in as.numeric( unlist( strsplit( as.character( map_file$group[row] ),',') ) ) ) {
      
      group.map <- rbind( group.map, 
                          list( map_file$sample_id[row],
                                group
                          ),
                          stringsAsFactors=FALSE
      )
    }
    
  } else {
    
    if ( !is.na( map_file[row,'group'] ) ) {
      
      group.map <- rbind( group.map,
                          list( map_file$sample_id[row],
                                map_file$group[row]
                          ),
                          stringsAsFactors=FALSE
      )
      
    }
    
  }
  
}
colnames( group.map ) <- c( 'sample_id', 'group' )

countfiles.path <- file.path( workdir.path, 'Countfiles_gene_symbol' )
if ( !dir.exists( countfiles.path ) ) {
  dir.create( countfiles.path )
}
seurat_files.path <- file.path( workdir.path, 'seurat_files' )
if ( !dir.exists( seurat_files.path ) ) {
  dir.create( seurat_files.path )
}
pdfdir.path <- file.path( workdir.path, 'pdfs' )
if ( !dir.exists( pdfdir.path ) ) {
  dir.create( pdfdir.path )
}

# Map the first file's Ensemble IDs to gene symbols:
ensg.genes.path <- file.path( workdir.path, 'ensg.genes' )
if ( file_test( '-f', ensg.genes.path ) ) {
  
  # If it already exists, use the pre-existing map.
  message( paste0( "Found ", ensg.genes.path, ', and will use it instead of making it again.' ) )
  ensg.genes = fread( ensg.genes.path )
  
} else {
  
  # biomart is notoriously fickle.  Might have to do this a few times
  tries <- 0
  max_tries <- 3
  
  while ( !file_test( '-f', ensg.genes.path ) && tries < max_tries ) {

    tries <- tries + 1
    message( paste0( 'Creating ensg2symbol mapping file, attempt ', tries ) )    
    dt <- as.data.frame( fread( input_files[1] ) )
    names( dt )[1] <- 'ENSG'
    dt <- as.data.table( dt )
    ensg.genes <- data.table( 'ENSG' = dt$ENSG )
    genes <- ensg.genes$ENSG
    mart <- useDataset( "hsapiens_gene_ensembl", useMart( "ensembl" ) )
    G_list <- getBM( filters='ensembl_gene_id', attributes=c( 'ensembl_gene_id', 'external_gene_name' ), values=genes, mart=mart )
    G_list <- as.data.table( G_list )
    ensg.genes <- merge( ensg.genes, G_list, all=T, by.x="ENSG", by.y="ensembl_gene_id" )
    ensg.genes <- na.omit( ensg.genes )
    # Now can use G_list to merge the list from each file together by symbol.  So why not save it for this run?
    fwrite( ensg.genes, ensg.genes.path, col.names=T, row.names=F, sep=',' )
    
  }
  
  if ( !file_test( '-f', ensg.genes.path ) ) {
    stop( "Couldn't create the ensg2symbol mapping." )
  }
  
}

# TODO: Filter out 'blacklisted' genes


# Just kinda pulling this out to avoid wall o' code
reformat_for_seurat <- function( x, samplename ) {
  x <- x[external_gene_name != "NA", ]
  x <- as.data.frame(x)
  
  row.names(x) <- x$external_gene_name
  x <- x[-1]
  barcodes <- names(x)
  barcodes <- paste0( barcodes, paste0( ".", samplename ) )
  names(x) <- barcodes
  x <- CreateSeuratObject( counts = x, 
                           project = as.character( map_file$library[ map_file$sample_id == samplename ] )
                          )
  x@meta.data$sample <- samplename
  return(x)
}

seurat_files <- list()
message( "Creating Seurat Objects" )
mcoptions=list( silent=TRUE )
foreach ( input_file=iter( input_files ) ) %dopar% {

  sample_id <- str_split_fixed( input_file, ".csv", 2 )[1]
  sample_id <- basename( sample_id )
  message( paste( "Working on", sample_id, sep=" " ) )
  
  dt <- as.data.frame( fread( input_file ) )
  names(dt)[1] <- 'ENSG'
  dt <- as.data.table(dt)
  dt <- subset( dt, dt$ENSG %in% ensg.genes$ENSG )
  dt <- merge( dt, ensg.genes, by = 'ENSG' )
  dt <- dt[ , ENSG:=NULL ]
  dt <- dt[ !duplicated( external_gene_name ), ]
  cols <- names(dt)[ c( 1:( length( names(dt) )-1 ) ) ]
  dt<- subset( dt, select=c( "external_gene_name", cols ) )
  fwrite( dt, paste0( countfiles.path, '/', sample_id, '_gene_symbol.csv'), col.names=T, row.names=F, quote=F, sep="," )
  
  # Make the seurat object (so)
  so <- reformat_for_seurat( dt, sample_id )
  
  seurat_filename <- paste0( seurat_files.path, '/', sample_id, '.seurat.Rdata' )
  save( so, file=seurat_filename )
  
  message( paste( "Finished with", sample_id, sep=" ") )
  
}

# Need to use a seperate loop to add merged files to the list of seurat files,
# since %dopar% has no way of sharing objects between threads.
for ( input_file in input_files ) {
  
  sample_id <- str_split_fixed( input_file, ".csv", 2 )[1]
  sample_id <- basename( sample_id )
  seurat_file <-paste0( sample_id, '.seurat.Rdata' )
  seurat_files <- append( seurat_files, seurat_file )

}

# merge each group as neccessary:
message( "Merging seurat objects" )
setwd( seurat_files.path )
foreach ( group_x =iter( sort( unique( group.map$group ) ) ) ) %dopar% {
  
  group.subset <- subset( group.map, group==group_x )
  if ( nrow( group.subset ) == 1 ) 
    return(NULL)  # Looks strange, think "next" but for "%dopar%" since
                  # foreach ... %dopar% is more like 'lapply' than 'for'
  
  message( "Merging group ", group_x )
  
  sample_one.file <- paste0( group.subset$sample_id[1], '.seurat.Rdata' )
  # loading created the object names 'so' because it was named that way initially 
  load( sample_one.file )
  group.merged <- so
  if ( nrow( group.subset ) > 1)  {

    for ( sample_id in group.subset[ 2:nrow(group.subset), ]$sample_id ) {

      sample_n.file <- paste0( sample_id, '.seurat.Rdata' )
      load( sample_n.file )
      group.merged <- merge( group.merged, so )

    }

  }
  group.merged.file <- paste0( 'group_', group_x, '.merged.seurat.Rdata' )
  
  message( "Saving group file: ", group.merged.file )
  
  save( group.merged, file=file.path( group.merged.file ) )
 
}

# Need to use a seperate loop to add merged files to the list of seurat files,
# since %dopar% has no way of sharing objects between threads.
# Althouhg... maybe using .combine would work? 
for ( group_x in sort( unique( group.map$group ) ) ) {

  group.subset <- subset( group.map,group==group_x )
  if ( nrow( group.subset ) > 1 ) {

    group.merged.file <- paste0( 'group_', group_x, '.merged.seurat.Rdata' )
    seurat_files <- append( seurat_files, group.merged.file )

  }

}

message( "Processing Seurat objects" )
pdfs <- list()

#for ( this in iter(seurat_files) ) {
#  message("Found", this)
#}
#stop("foo")
#message("Testing....")
#message( seurat_files )
#foreach ( seurat_filepath=iter( seurat_files ), options.multicore=mcoptions, preschedule=F ) %dopar% {
#foreach ( seurat_filepath=iter( seurat_files ) ) %dopar% {
# 
#    message( "Here:", seurat_filepath)
#   
#}
#stop("Done testing")

# Ugh not sure why preschedule=F suddenly stopped processing everything but the first job.
# Until it gets straightened out, resort to %do%, because without it %dopar% invariably 
# fails each time for a single job.  Note to self: Might need to specify a different number of cores?
#foreach ( seurat_filepath=iter( seurat_files ), options.multicore=mcoptions, preschedule=F ) %dopar% {
foreach ( seurat_filepath=iter( seurat_files ) ) %do% {
    
  message( "Working on:", seurat_filepath )
  load( seurat_filepath )
  
  newname <- str_replace( basename( seurat_filepath ), "\\.seurat\\.Rdata", "" )
  if ( str_detect( newname, "group_" ) ) {
    x <- group.merged
  } else {
    x <- so
  }
  
  message( 'Normalizing Data' )
  x <- NormalizeData(x)

  message( 'Finding Variable Features' )
  x <- FindVariableFeatures(x)

  message( 'Scaling Data' )
  x <- ScaleData( x, features = row.names( as.data.frame( x@assays$RNA@data ) ) )
  Idents(x) <- 'sample'

  message( 'Running PCA' )
  x <- RunPCA(x)
  pdffile = str_replace( seurat_filepath, "seurat\\.Rdata", "pcaplot.pdf" )
  pdfs[[pdffile]] <- PCAPlot( x, pt.size = 1 )
  
  message( 'Finding Neighbor' )
  x <- FindNeighbors(x)

  message( 'Finding Clusters' )
  x <- FindClusters(x)
  
  message( 'Running tSNE' )
  x <- RunTSNE(x)
  pdffile = str_replace( seurat_filepath, "seurat\\.Rdata", "tsneplot.pdf" )
  pdfs[[pdffile]] <- TSNEPlot( x, pt.size = 1 )
  
  message( 'Running UMAP' )
  x <- RunUMAP( x, dims=1:5 )
  pdffile = str_replace( seurat_filepath, "seurat\\.Rdata", "umapplot.pdf" )
  pdfs[[pdffile]] <- UMAPPlot( x, pt.size = 1 )
  
  
  if ( str_detect( newname, 'group_') )  {
  
    message( 'Running FindAllMarkers')
    DE_markers <- FindAllMarkers(x)
  
    clusters_up   <- setorder( setDT( DE_markers ), -avg_logFC )[ , head( .SD, 100 ), keyby='cluster' ]
    clusters_down <- setorder( setDT( DE_markers ),  avg_logFC )[ , head( .SD, 100 ), keyby='cluster' ]
  
    pdffile = str_replace( seurat_filepath, "seurat\\.Rdata", "heatmap.pdf" )
    pdfs[[pdffile]] <- DoHeatmap( x, features = c( clusters_up$V1, clusters_down$V1 ), raster=F ) +
      scale_fill_gradientn( colors = rev( RColorBrewer::brewer.pal( n = 10, name = "RdBu" )) ) +
      guides( color = FALSE)

  }
  
  message( 'Saving Final Seurat Object: ', newname )
  assign( newname, x )
  
  save( list=c( newname ), file=seurat_filepath )
  
}

# Print the pdfs generated above
message( 'Writing pdfs to: ', pdfdir.path )

pdfs

setwd( pdfdir.path )

for ( pdffile in pdfs ) {
 
  pdf(pdffile)
  pdfs[[pdffile]]
  dev.off()

}

# TODO: continue with some downstream tools like enrichR (after running FindALlMarkers), etc.
